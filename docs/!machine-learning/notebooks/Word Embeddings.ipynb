{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors\n",
    "\n",
    "Vectors are useful since they help us summarize information about an object using numbers. Then, using the number representation, we can make comparisons between the vector representations of different objects.\n",
    "\n",
    "Say you are working at a school and want to analyze student scores.\n",
    "Take a look at the vectors representing the student's scores plotted below. What do you notice? Are they close together? How similar is the vector for Alena’s scores to Xavier’s and Niko’s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1f53fcdac8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_xavier = np.array([88,92])\n",
    "scores_niko   = np.array([94,87])\n",
    "scores_alena  = np.array([90,48])\n",
    "\n",
    "plt.arrow(0, 0, scores_xavier[0], scores_xavier[1], width=1, color='blue', label='xavier')\n",
    "plt.arrow(0, 0, scores_niko[0],   scores_niko[1], width=1, color='orange', label='niko')\n",
    "plt.arrow(0, 0, scores_alena[0],  scores_alena[1], width=1, color='purple', label='alena')\n",
    "\n",
    "plt.axis([0, 100, 0, 100])\n",
    "plt.legend(bbox_to_anchor=(1,1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance\n",
    "\n",
    "There are a variety of ways to find the distance between vectors, and here we will cover three.\n",
    "\n",
    "1. <ins>Manhattan distance</ins>  \n",
    "    Manhattan distance, also known as city block distance, is defined as the sum of the differences across each individual dimension of the vectors. Consider the vectors [1,2,3] and [2,4,6]. We can calculate the Manhattan distance between them as shown below:\n",
    "\n",
    "        manhattan distance = ∣1−2∣ + ∣2−4∣ + ∣3−6∣ = 1 + 2 + 3 = 6\n",
    "\n",
    "2. <ins>Euclidean distance</ins>  \n",
    "   In Euclidean distance, also known as straight line distance, we take the square root of the sum of the squares of the differences in each dimension.\n",
    "\n",
    "        euclidean distance = √{(1−2)^2 + (2−4)^2 + (3−6)^2}\n",
    "                           = √{14} ≈ 3.74\n",
    "\n",
    "3. <ins>Cosine distance</ins>  \n",
    "   Cosine distance is concerned with the angle between two vectors, rather than by looking at the distance between the points, or ends, of the vectors. Two vectors that point in the same direction have no angle between them, and have a cosine distance of 0. Two vectors that point in opposite directions, on the other hand, have a cosine distance of 1. For the mathematically adventurous, [you can read up on the calculation here](https://en.wikipedia.org/wiki/Cosine_similarity#Definition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1f51ecd2e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_a = np.array([1,2,3])\n",
    "vector_b = np.array([2,4,6])\n",
    "\n",
    "plt.arrow(0, 0, vector_b[0], vector_b[1], width=.05, color='orange', label='b')\n",
    "plt.arrow(0, 0, vector_a[0], vector_a[1], width=.05, color='blue', label='a')\n",
    "\n",
    "plt.axis([0, 3, 0, 6])\n",
    "plt.legend(bbox_to_anchor=(1,1), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cityblock, euclidean, cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance: 6\n",
      "Euclidean distance: 3.7416573867739413\n",
      "Cosine distance:    0.0\n"
     ]
    }
   ],
   "source": [
    "print('Manhattan distance:', cityblock(vector_a,vector_b))\n",
    "print('Euclidean distance:', euclidean(vector_a,vector_b))\n",
    "print('Cosine distance:   ', cosine(vector_a,vector_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with vectors that have a large number of dimensions, such as word embeddings, the distances calculated by Manhattan and Euclidean distance can become rather large. Thus, calculations using cosine distance are usually preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "* Word embeddings are vector representations of a word.  \n",
    "The idea behind word embeddings is a theory known as the distributional hypothesis. This hypothesis states that words that co-occur in the same contexts tend to have similar meanings. With word embeddings, we map words that exist with the same context to similar places in our vector space (math-speak for the area in which our vectors exist). Example:\n",
    "\n",
    "    <pre>\n",
    "    The <ins>kid</ins> said he would grow up to be superman\n",
    "    The <ins>child</ins> said he would grow up to be superman</pre>\n",
    "    \n",
    "    The words kid and child will have similar word vectors due to a similar context.  \n",
    "    Note: Embedding can be considered as a synonym for encoding.<br><br>\n",
    "\n",
    "* The numeric values that are assigned to the vector representation of a word are not important in their own right, but gather meaning from how similar or not words are to each other. Thus the cosine distance between words with similar contexts will be small, and the cosine distance between words that have very different contexts will be large.<br><br>\n",
    "\n",
    "* We can retrieve word embeddings for english words using [spaCy](https://spacy.io/models/en):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_vec = nlp('happy').vector\n",
    "sad_vec   = nlp('sad').vector\n",
    "angry_vec = nlp('angry').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(happy_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy/sad: 0.35610121488571167\n",
      "angry/sad: 0.3968866467475891\n"
     ]
    }
   ],
   "source": [
    "# Cosine distance\n",
    "print('happy/sad:', cosine(happy_vec, sad_vec))\n",
    "print('angry/sad:', cosine(angry_vec, sad_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of 1,000 most common English words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = ['a',\n",
    " 'ability',\n",
    " 'able',\n",
    " 'about',\n",
    " 'above',\n",
    " 'accept',\n",
    " 'according',\n",
    " 'account',\n",
    " 'across',\n",
    " 'act',\n",
    " 'action',\n",
    " 'activity',\n",
    " 'actually',\n",
    " 'add',\n",
    " 'address',\n",
    " 'administration',\n",
    " 'admit',\n",
    " 'adult',\n",
    " 'affect',\n",
    " 'after',\n",
    " 'again',\n",
    " 'against',\n",
    " 'age',\n",
    " 'agency',\n",
    " 'agent',\n",
    " 'ago',\n",
    " 'agree',\n",
    " 'agreement',\n",
    " 'ahead',\n",
    " 'air',\n",
    " 'all',\n",
    " 'allow',\n",
    " 'almost',\n",
    " 'alone',\n",
    " 'along',\n",
    " 'already',\n",
    " 'also',\n",
    " 'although',\n",
    " 'always',\n",
    " 'American',\n",
    " 'among',\n",
    " 'amount',\n",
    " 'analysis',\n",
    " 'and',\n",
    " 'animal',\n",
    " 'another',\n",
    " 'answer',\n",
    " 'any',\n",
    " 'anyone',\n",
    " 'anything',\n",
    " 'appear',\n",
    " 'apply',\n",
    " 'approach',\n",
    " 'area',\n",
    " 'argue',\n",
    " 'arm',\n",
    " 'around',\n",
    " 'arrive',\n",
    " 'art',\n",
    " 'article',\n",
    " 'artist',\n",
    " 'as',\n",
    " 'ask',\n",
    " 'assume',\n",
    " 'at',\n",
    " 'attack',\n",
    " 'attention',\n",
    " 'attorney',\n",
    " 'audience',\n",
    " 'author',\n",
    " 'authority',\n",
    " 'available',\n",
    " 'avoid',\n",
    " 'away',\n",
    " 'baby',\n",
    " 'back',\n",
    " 'bad',\n",
    " 'bag',\n",
    " 'ball',\n",
    " 'bank',\n",
    " 'bar',\n",
    " 'base',\n",
    " 'be',\n",
    " 'beat',\n",
    " 'beautiful',\n",
    " 'because',\n",
    " 'become',\n",
    " 'bed',\n",
    " 'before',\n",
    " 'begin',\n",
    " 'behavior',\n",
    " 'behind',\n",
    " 'believe',\n",
    " 'benefit',\n",
    " 'best',\n",
    " 'better',\n",
    " 'between',\n",
    " 'beyond',\n",
    " 'big',\n",
    " 'bill',\n",
    " 'billion',\n",
    " 'bit',\n",
    " 'black',\n",
    " 'blood',\n",
    " 'blue',\n",
    " 'board',\n",
    " 'body',\n",
    " 'book',\n",
    " 'born',\n",
    " 'both',\n",
    " 'box',\n",
    " 'boy',\n",
    " 'break',\n",
    " 'bring',\n",
    " 'brother',\n",
    " 'budget',\n",
    " 'build',\n",
    " 'building',\n",
    " 'business',\n",
    " 'but',\n",
    " 'buy',\n",
    " 'by',\n",
    " 'call',\n",
    " 'camera',\n",
    " 'campaign',\n",
    " 'can',\n",
    " 'cancer',\n",
    " 'candidate',\n",
    " 'capital',\n",
    " 'car',\n",
    " 'card',\n",
    " 'care',\n",
    " 'career',\n",
    " 'carry',\n",
    " 'case',\n",
    " 'catch',\n",
    " 'cause',\n",
    " 'cell',\n",
    " 'center',\n",
    " 'central',\n",
    " 'century',\n",
    " 'certain',\n",
    " 'certainly',\n",
    " 'chair',\n",
    " 'challenge',\n",
    " 'chance',\n",
    " 'change',\n",
    " 'character',\n",
    " 'charge',\n",
    " 'check',\n",
    " 'child',\n",
    " 'choice',\n",
    " 'choose',\n",
    " 'church',\n",
    " 'citizen',\n",
    " 'city',\n",
    " 'civil',\n",
    " 'claim',\n",
    " 'class',\n",
    " 'clear',\n",
    " 'clearly',\n",
    " 'close',\n",
    " 'coach',\n",
    " 'cold',\n",
    " 'collection',\n",
    " 'college',\n",
    " 'color',\n",
    " 'come',\n",
    " 'commercial',\n",
    " 'common',\n",
    " 'community',\n",
    " 'company',\n",
    " 'compare',\n",
    " 'computer',\n",
    " 'concern',\n",
    " 'condition',\n",
    " 'conference',\n",
    " 'Congress',\n",
    " 'consider',\n",
    " 'consumer',\n",
    " 'contain',\n",
    " 'continue',\n",
    " 'control',\n",
    " 'cost',\n",
    " 'could',\n",
    " 'country',\n",
    " 'couple',\n",
    " 'course',\n",
    " 'court',\n",
    " 'cover',\n",
    " 'create',\n",
    " 'crime',\n",
    " 'cultural',\n",
    " 'culture',\n",
    " 'cup',\n",
    " 'current',\n",
    " 'customer',\n",
    " 'cut',\n",
    " 'dark',\n",
    " 'data',\n",
    " 'daughter',\n",
    " 'day',\n",
    " 'dead',\n",
    " 'deal',\n",
    " 'death',\n",
    " 'debate',\n",
    " 'decade',\n",
    " 'decide',\n",
    " 'decision',\n",
    " 'deep',\n",
    " 'defense',\n",
    " 'degree',\n",
    " 'Democrat',\n",
    " 'democratic',\n",
    " 'describe',\n",
    " 'design',\n",
    " 'despite',\n",
    " 'detail',\n",
    " 'determine',\n",
    " 'develop',\n",
    " 'development',\n",
    " 'die',\n",
    " 'difference',\n",
    " 'different',\n",
    " 'difficult',\n",
    " 'dinner',\n",
    " 'direction',\n",
    " 'director',\n",
    " 'discover',\n",
    " 'discuss',\n",
    " 'discussion',\n",
    " 'disease',\n",
    " 'do',\n",
    " 'doctor',\n",
    " 'dog',\n",
    " 'door',\n",
    " 'down',\n",
    " 'draw',\n",
    " 'dream',\n",
    " 'drive',\n",
    " 'drop',\n",
    " 'drug',\n",
    " 'during',\n",
    " 'each',\n",
    " 'early',\n",
    " 'east',\n",
    " 'easy',\n",
    " 'eat',\n",
    " 'economic',\n",
    " 'economy',\n",
    " 'edge',\n",
    " 'education',\n",
    " 'effect',\n",
    " 'effort',\n",
    " 'eight',\n",
    " 'either',\n",
    " 'election',\n",
    " 'else',\n",
    " 'employee',\n",
    " 'end',\n",
    " 'energy',\n",
    " 'enjoy',\n",
    " 'enough',\n",
    " 'enter',\n",
    " 'entire',\n",
    " 'environment',\n",
    " 'environmental',\n",
    " 'especially',\n",
    " 'establish',\n",
    " 'even',\n",
    " 'evening',\n",
    " 'event',\n",
    " 'ever',\n",
    " 'every',\n",
    " 'everybody',\n",
    " 'everyone',\n",
    " 'everything',\n",
    " 'evidence',\n",
    " 'exactly',\n",
    " 'example',\n",
    " 'executive',\n",
    " 'exist',\n",
    " 'expect',\n",
    " 'experience',\n",
    " 'expert',\n",
    " 'explain',\n",
    " 'eye',\n",
    " 'face',\n",
    " 'fact',\n",
    " 'factor',\n",
    " 'fail',\n",
    " 'fall',\n",
    " 'family',\n",
    " 'far',\n",
    " 'fast',\n",
    " 'father',\n",
    " 'fear',\n",
    " 'federal',\n",
    " 'feel',\n",
    " 'feeling',\n",
    " 'few',\n",
    " 'field',\n",
    " 'fight',\n",
    " 'figure',\n",
    " 'fill',\n",
    " 'film',\n",
    " 'final',\n",
    " 'finally',\n",
    " 'financial',\n",
    " 'find',\n",
    " 'fine',\n",
    " 'finger',\n",
    " 'finish',\n",
    " 'fire',\n",
    " 'firm',\n",
    " 'first',\n",
    " 'fish',\n",
    " 'five',\n",
    " 'floor',\n",
    " 'fly',\n",
    " 'focus',\n",
    " 'follow',\n",
    " 'food',\n",
    " 'foot',\n",
    " 'for',\n",
    " 'force',\n",
    " 'foreign',\n",
    " 'forget',\n",
    " 'form',\n",
    " 'former',\n",
    " 'forward',\n",
    " 'four',\n",
    " 'free',\n",
    " 'friend',\n",
    " 'from',\n",
    " 'front',\n",
    " 'full',\n",
    " 'fund',\n",
    " 'future',\n",
    " 'game',\n",
    " 'garden',\n",
    " 'gas',\n",
    " 'general',\n",
    " 'generation',\n",
    " 'get',\n",
    " 'girl',\n",
    " 'give',\n",
    " 'glass',\n",
    " 'go',\n",
    " 'goal',\n",
    " 'good',\n",
    " 'government',\n",
    " 'great',\n",
    " 'green',\n",
    " 'ground',\n",
    " 'group',\n",
    " 'grow',\n",
    " 'growth',\n",
    " 'guess',\n",
    " 'gun',\n",
    " 'guy',\n",
    " 'hair',\n",
    " 'half',\n",
    " 'hand',\n",
    " 'hang',\n",
    " 'happen',\n",
    " 'happy',\n",
    " 'hard',\n",
    " 'have',\n",
    " 'he',\n",
    " 'head',\n",
    " 'health',\n",
    " 'hear',\n",
    " 'heart',\n",
    " 'heat',\n",
    " 'heavy',\n",
    " 'help',\n",
    " 'her',\n",
    " 'here',\n",
    " 'herself',\n",
    " 'high',\n",
    " 'him',\n",
    " 'himself',\n",
    " 'his',\n",
    " 'history',\n",
    " 'hit',\n",
    " 'hold',\n",
    " 'home',\n",
    " 'hope',\n",
    " 'hospital',\n",
    " 'hot',\n",
    " 'hotel',\n",
    " 'hour',\n",
    " 'house',\n",
    " 'how',\n",
    " 'however',\n",
    " 'huge',\n",
    " 'human',\n",
    " 'hundred',\n",
    " 'husband',\n",
    " 'I',\n",
    " 'idea',\n",
    " 'identify',\n",
    " 'if',\n",
    " 'image',\n",
    " 'imagine',\n",
    " 'impact',\n",
    " 'important',\n",
    " 'improve',\n",
    " 'in',\n",
    " 'include',\n",
    " 'including',\n",
    " 'increase',\n",
    " 'indeed',\n",
    " 'indicate',\n",
    " 'individual',\n",
    " 'industry',\n",
    " 'information',\n",
    " 'inside',\n",
    " 'instead',\n",
    " 'institution',\n",
    " 'interest',\n",
    " 'interesting',\n",
    " 'international',\n",
    " 'interview',\n",
    " 'into',\n",
    " 'investment',\n",
    " 'involve',\n",
    " 'issue',\n",
    " 'it',\n",
    " 'item',\n",
    " 'its',\n",
    " 'itself',\n",
    " 'job',\n",
    " 'join',\n",
    " 'just',\n",
    " 'keep',\n",
    " 'key',\n",
    " 'kid',\n",
    " 'kill',\n",
    " 'kind',\n",
    " 'kitchen',\n",
    " 'know',\n",
    " 'knowledge',\n",
    " 'land',\n",
    " 'language',\n",
    " 'large',\n",
    " 'last',\n",
    " 'late',\n",
    " 'later',\n",
    " 'laugh',\n",
    " 'law',\n",
    " 'lawyer',\n",
    " 'lay',\n",
    " 'lead',\n",
    " 'leader',\n",
    " 'learn',\n",
    " 'least',\n",
    " 'leave',\n",
    " 'left',\n",
    " 'leg',\n",
    " 'legal',\n",
    " 'less',\n",
    " 'let',\n",
    " 'letter',\n",
    " 'level',\n",
    " 'lie',\n",
    " 'life',\n",
    " 'light',\n",
    " 'like',\n",
    " 'likely',\n",
    " 'line',\n",
    " 'list',\n",
    " 'listen',\n",
    " 'little',\n",
    " 'live',\n",
    " 'local',\n",
    " 'long',\n",
    " 'look',\n",
    " 'lose',\n",
    " 'loss',\n",
    " 'lot',\n",
    " 'love',\n",
    " 'low',\n",
    " 'machine',\n",
    " 'magazine',\n",
    " 'main',\n",
    " 'maintain',\n",
    " 'major',\n",
    " 'majority',\n",
    " 'make',\n",
    " 'man',\n",
    " 'manage',\n",
    " 'management',\n",
    " 'manager',\n",
    " 'many',\n",
    " 'market',\n",
    " 'marriage',\n",
    " 'material',\n",
    " 'matter',\n",
    " 'may',\n",
    " 'maybe',\n",
    " 'me',\n",
    " 'mean',\n",
    " 'measure',\n",
    " 'media',\n",
    " 'medical',\n",
    " 'meet',\n",
    " 'meeting',\n",
    " 'member',\n",
    " 'memory',\n",
    " 'mention',\n",
    " 'message',\n",
    " 'method',\n",
    " 'middle',\n",
    " 'might',\n",
    " 'military',\n",
    " 'million',\n",
    " 'mind',\n",
    " 'minute',\n",
    " 'miss',\n",
    " 'mission',\n",
    " 'model',\n",
    " 'modern',\n",
    " 'moment',\n",
    " 'money',\n",
    " 'month',\n",
    " 'more',\n",
    " 'morning',\n",
    " 'most',\n",
    " 'mother',\n",
    " 'mouth',\n",
    " 'move',\n",
    " 'movement',\n",
    " 'movie',\n",
    " 'Mr',\n",
    " 'Mrs',\n",
    " 'much',\n",
    " 'music',\n",
    " 'must',\n",
    " 'my',\n",
    " 'myself',\n",
    " 'name',\n",
    " 'nation',\n",
    " 'national',\n",
    " 'natural',\n",
    " 'nature',\n",
    " 'near',\n",
    " 'nearly',\n",
    " 'necessary',\n",
    " 'need',\n",
    " 'network',\n",
    " 'never',\n",
    " 'new',\n",
    " 'news',\n",
    " 'newspaper',\n",
    " 'next',\n",
    " 'nice',\n",
    " 'night',\n",
    " 'no',\n",
    " 'none',\n",
    " 'nor',\n",
    " 'north',\n",
    " 'not',\n",
    " 'note',\n",
    " 'nothing',\n",
    " 'notice',\n",
    " 'now',\n",
    " \"n't\",\n",
    " 'number',\n",
    " 'occur',\n",
    " 'of',\n",
    " 'off',\n",
    " 'offer',\n",
    " 'office',\n",
    " 'officer',\n",
    " 'official',\n",
    " 'often',\n",
    " 'oh',\n",
    " 'oil',\n",
    " 'ok',\n",
    " 'old',\n",
    " 'on',\n",
    " 'once',\n",
    " 'one',\n",
    " 'only',\n",
    " 'onto',\n",
    " 'open',\n",
    " 'operation',\n",
    " 'opportunity',\n",
    " 'option',\n",
    " 'or',\n",
    " 'order',\n",
    " 'organization',\n",
    " 'other',\n",
    " 'others',\n",
    " 'our',\n",
    " 'out',\n",
    " 'outside',\n",
    " 'over',\n",
    " 'own',\n",
    " 'owner',\n",
    " 'page',\n",
    " 'pain',\n",
    " 'painting',\n",
    " 'paper',\n",
    " 'parent',\n",
    " 'part',\n",
    " 'participant',\n",
    " 'particular',\n",
    " 'particularly',\n",
    " 'partner',\n",
    " 'party',\n",
    " 'pass',\n",
    " 'past',\n",
    " 'patient',\n",
    " 'pattern',\n",
    " 'pay',\n",
    " 'peace',\n",
    " 'people',\n",
    " 'per',\n",
    " 'perform',\n",
    " 'performance',\n",
    " 'perhaps',\n",
    " 'period',\n",
    " 'person',\n",
    " 'personal',\n",
    " 'phone',\n",
    " 'physical',\n",
    " 'pick',\n",
    " 'picture',\n",
    " 'piece',\n",
    " 'place',\n",
    " 'plan',\n",
    " 'plant',\n",
    " 'play',\n",
    " 'player',\n",
    " 'PM',\n",
    " 'point',\n",
    " 'police',\n",
    " 'policy',\n",
    " 'political',\n",
    " 'politics',\n",
    " 'poor',\n",
    " 'popular',\n",
    " 'population',\n",
    " 'position',\n",
    " 'positive',\n",
    " 'possible',\n",
    " 'power',\n",
    " 'practice',\n",
    " 'prepare',\n",
    " 'present',\n",
    " 'president',\n",
    " 'pressure',\n",
    " 'pretty',\n",
    " 'prevent',\n",
    " 'price',\n",
    " 'private',\n",
    " 'probably',\n",
    " 'problem',\n",
    " 'process',\n",
    " 'produce',\n",
    " 'product',\n",
    " 'production',\n",
    " 'professional',\n",
    " 'professor',\n",
    " 'program',\n",
    " 'project',\n",
    " 'property',\n",
    " 'protect',\n",
    " 'prove',\n",
    " 'provide',\n",
    " 'public',\n",
    " 'pull',\n",
    " 'purpose',\n",
    " 'push',\n",
    " 'put',\n",
    " 'quality',\n",
    " 'question',\n",
    " 'quickly',\n",
    " 'quite',\n",
    " 'race',\n",
    " 'radio',\n",
    " 'raise',\n",
    " 'range',\n",
    " 'rate',\n",
    " 'rather',\n",
    " 'reach',\n",
    " 'read',\n",
    " 'ready',\n",
    " 'real',\n",
    " 'reality',\n",
    " 'realize',\n",
    " 'really',\n",
    " 'reason',\n",
    " 'receive',\n",
    " 'recent',\n",
    " 'recently',\n",
    " 'recognize',\n",
    " 'record',\n",
    " 'red',\n",
    " 'reduce',\n",
    " 'reflect',\n",
    " 'region',\n",
    " 'relate',\n",
    " 'relationship',\n",
    " 'religious',\n",
    " 'remain',\n",
    " 'remember',\n",
    " 'remove',\n",
    " 'report',\n",
    " 'represent',\n",
    " 'Republican',\n",
    " 'require',\n",
    " 'research',\n",
    " 'resource',\n",
    " 'respond',\n",
    " 'response',\n",
    " 'responsibility',\n",
    " 'rest',\n",
    " 'result',\n",
    " 'return',\n",
    " 'reveal',\n",
    " 'rich',\n",
    " 'right',\n",
    " 'rise',\n",
    " 'risk',\n",
    " 'road',\n",
    " 'rock',\n",
    " 'role',\n",
    " 'room',\n",
    " 'rule',\n",
    " 'run',\n",
    " 'safe',\n",
    " 'same',\n",
    " 'save',\n",
    " 'say',\n",
    " 'scene',\n",
    " 'school',\n",
    " 'science',\n",
    " 'scientist',\n",
    " 'score',\n",
    " 'sea',\n",
    " 'season',\n",
    " 'seat',\n",
    " 'second',\n",
    " 'section',\n",
    " 'security',\n",
    " 'see',\n",
    " 'seek',\n",
    " 'seem',\n",
    " 'sell',\n",
    " 'send',\n",
    " 'senior',\n",
    " 'sense',\n",
    " 'series',\n",
    " 'serious',\n",
    " 'serve',\n",
    " 'service',\n",
    " 'set',\n",
    " 'seven',\n",
    " 'several',\n",
    " 'sex',\n",
    " 'sexual',\n",
    " 'shake',\n",
    " 'share',\n",
    " 'she',\n",
    " 'shoot',\n",
    " 'short',\n",
    " 'shot',\n",
    " 'should',\n",
    " 'shoulder',\n",
    " 'show',\n",
    " 'side',\n",
    " 'sign',\n",
    " 'significant',\n",
    " 'similar',\n",
    " 'simple',\n",
    " 'simply',\n",
    " 'since',\n",
    " 'sing',\n",
    " 'single',\n",
    " 'sister',\n",
    " 'sit',\n",
    " 'site',\n",
    " 'situation',\n",
    " 'six',\n",
    " 'size',\n",
    " 'skill',\n",
    " 'skin',\n",
    " 'small',\n",
    " 'smile',\n",
    " 'so',\n",
    " 'social',\n",
    " 'society',\n",
    " 'soldier',\n",
    " 'some',\n",
    " 'somebody',\n",
    " 'someone',\n",
    " 'something',\n",
    " 'sometimes',\n",
    " 'son',\n",
    " 'song',\n",
    " 'soon',\n",
    " 'sort',\n",
    " 'sound',\n",
    " 'source',\n",
    " 'south',\n",
    " 'southern',\n",
    " 'space',\n",
    " 'speak',\n",
    " 'special',\n",
    " 'specific',\n",
    " 'speech',\n",
    " 'spend',\n",
    " 'sport',\n",
    " 'spring',\n",
    " 'staff',\n",
    " 'stage',\n",
    " 'stand',\n",
    " 'standard',\n",
    " 'star',\n",
    " 'start',\n",
    " 'state',\n",
    " 'statement',\n",
    " 'station',\n",
    " 'stay',\n",
    " 'step',\n",
    " 'still',\n",
    " 'stock',\n",
    " 'stop',\n",
    " 'store',\n",
    " 'story',\n",
    " 'strategy',\n",
    " 'street',\n",
    " 'strong',\n",
    " 'structure',\n",
    " 'student',\n",
    " 'study',\n",
    " 'stuff',\n",
    " 'style',\n",
    " 'subject',\n",
    " 'success',\n",
    " 'successful',\n",
    " 'such',\n",
    " 'suddenly',\n",
    " 'suffer',\n",
    " 'suggest',\n",
    " 'summer',\n",
    " 'support',\n",
    " 'sure',\n",
    " 'surface',\n",
    " 'system',\n",
    " 'table',\n",
    " 'take',\n",
    " 'talk',\n",
    " 'task',\n",
    " 'tax',\n",
    " 'teach',\n",
    " 'teacher',\n",
    " 'team',\n",
    " 'technology',\n",
    " 'television',\n",
    " 'tell',\n",
    " 'ten',\n",
    " 'tend',\n",
    " 'term',\n",
    " 'test',\n",
    " 'than',\n",
    " 'thank',\n",
    " 'that',\n",
    " 'the',\n",
    " 'their',\n",
    " 'them',\n",
    " 'themselves',\n",
    " 'then',\n",
    " 'theory',\n",
    " 'there',\n",
    " 'these',\n",
    " 'they',\n",
    " 'thing',\n",
    " 'think',\n",
    " 'third',\n",
    " 'this',\n",
    " 'those',\n",
    " 'though',\n",
    " 'thought',\n",
    " 'thousand',\n",
    " 'threat',\n",
    " 'three',\n",
    " 'through',\n",
    " 'throughout',\n",
    " 'throw',\n",
    " 'thus',\n",
    " 'time',\n",
    " 'to',\n",
    " 'today',\n",
    " 'together',\n",
    " 'tonight',\n",
    " 'too',\n",
    " 'top',\n",
    " 'total',\n",
    " 'tough',\n",
    " 'toward',\n",
    " 'town',\n",
    " 'trade',\n",
    " 'traditional',\n",
    " 'training',\n",
    " 'travel',\n",
    " 'treat',\n",
    " 'treatment',\n",
    " 'tree',\n",
    " 'trial',\n",
    " 'trip',\n",
    " 'trouble',\n",
    " 'true',\n",
    " 'truth',\n",
    " 'try',\n",
    " 'turn',\n",
    " 'TV',\n",
    " 'two',\n",
    " 'type',\n",
    " 'under',\n",
    " 'understand',\n",
    " 'unit',\n",
    " 'until',\n",
    " 'up',\n",
    " 'upon',\n",
    " 'us',\n",
    " 'use',\n",
    " 'usually',\n",
    " 'value',\n",
    " 'various',\n",
    " 'very',\n",
    " 'victim',\n",
    " 'view',\n",
    " 'violence',\n",
    " 'visit',\n",
    " 'voice',\n",
    " 'vote',\n",
    " 'wait',\n",
    " 'walk',\n",
    " 'wall',\n",
    " 'want',\n",
    " 'war',\n",
    " 'watch',\n",
    " 'water',\n",
    " 'way',\n",
    " 'we',\n",
    " 'weapon',\n",
    " 'wear',\n",
    " 'week',\n",
    " 'weight',\n",
    " 'well',\n",
    " 'west',\n",
    " 'western',\n",
    " 'what',\n",
    " 'whatever',\n",
    " 'when',\n",
    " 'where',\n",
    " 'whether',\n",
    " 'which',\n",
    " 'while',\n",
    " 'white',\n",
    " 'who',\n",
    " 'whole',\n",
    " 'whom',\n",
    " 'whose',\n",
    " 'why',\n",
    " 'wide',\n",
    " 'wife',\n",
    " 'will',\n",
    " 'win',\n",
    " 'wind',\n",
    " 'window',\n",
    " 'wish',\n",
    " 'with',\n",
    " 'within',\n",
    " 'without',\n",
    " 'woman',\n",
    " 'wonder',\n",
    " 'word',\n",
    " 'work',\n",
    " 'worker',\n",
    " 'world',\n",
    " 'worry',\n",
    " 'would',\n",
    " 'write',\n",
    " 'writer',\n",
    " 'wrong',\n",
    " 'yard',\n",
    " 'yeah',\n",
    " 'year',\n",
    " 'yes',\n",
    " 'yet',\n",
    " 'you',\n",
    " 'young',\n",
    " 'your',\n",
    " 'yourself']\n",
    "\n",
    "len(most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and their corresponding word embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_list = [nlp(x).vector for x in most_common_words]\n",
    "len(vector_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which words are the closest to \"food\" — by retrieving word embeddings that are the closest to its word embedding. Are you surprised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food',\n",
       " 'eat',\n",
       " 'dinner',\n",
       " 'fish',\n",
       " 'health',\n",
       " 'kitchen',\n",
       " 'good',\n",
       " 'animal',\n",
       " 'water',\n",
       " 'treat']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_closest_words(word, n=10):\n",
    "    global most_common_words, vector_list\n",
    "\n",
    "    vec = vector_list[most_common_words.index(word)]\n",
    "\n",
    "    return sorted(most_common_words,\n",
    "           key=lambda x: cosine(\n",
    "               vector_list[most_common_words.index(x)],\n",
    "               vec\n",
    "          ))[:n]\n",
    "\n",
    "find_closest_words('food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summer',\n",
       " 'spring',\n",
       " 'fall',\n",
       " 'season',\n",
       " 'year',\n",
       " 'week',\n",
       " 'day',\n",
       " 'evening',\n",
       " 'during',\n",
       " 'last']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_words('summer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own Words embeddings\n",
    "\n",
    "* Depending on the corpus of text we select to train a word embedding model, different word embeddings will be created according to the context of the words in the given corpus. The larger and more generic a corpus, the more generalizable the word embeddings become.\n",
    "\n",
    "  So far, we have been using pre-trained word embedding models stored in spaCy. These models were trained (using word2vec) on blog posts and news articles collected by the [Linguistic Data Consortium](https://catalog.ldc.upenn.edu/LDC2013T19) at the University of Pennsylvania.<br><br>\n",
    "\n",
    "* What if we want to train our own word embeddings?  \n",
    "  Different algorithms (and models) have been developed to create word embeddings from a corpus of text:\n",
    "\n",
    "    * [Word2Vec](https://code.google.com/archive/p/word2vec/):  \n",
    "        Word2Vec was created by Google researchers (Tomas Mikolov, Kai Chen, Greg Corrado and Jefrrey Dean) in 2013. They provided a model with 300 dimensions, trained on 3 million words from Google News data. Team used skip-gram and negative sampling to build this model.<br><br>\n",
    "\n",
    "    * [GloVe](https://nlp.stanford.edu/projects/glove/):  \n",
    "      Global Vectors for word representation (GloVe) was created by Stanford researchers (Jeffrey Pennington, Richard Socher and Chris Manning) in 2014. They provided various models from 25, 50, 100, 200 to 300 dimensions based on 2, 6, 42, 840 billion tokens. Team used word-to-word co-occurrence to build this model — in other words, if two words co-occur many times, it means they have some linguistic or semantic similarity.<br><br>\n",
    "\n",
    "    * [fastText](https://fasttext.cc/):  \n",
    "        fastText was developed by Facebook. They provide 3 models with 300 dimensions each. fastText is able to achieve good performance for word representations and sentence classifications because they are making use of character level representations. Each word is represented as bag of characters n-grams in addition to the word itself. For example, for the word partial, with n=3, the fastText representation for the character n-grams is &lt;pa, art, rti, tia, ial, al&gt;. &lt;and&gt; are added as boundary symbols to separate the n-grams from the word itself.<br><br>\n",
    "\n",
    "* Word2vec tends to be the most popular. The package [gensim](https://radimrehurek.com/gensim/) has a  Word2Vec() function that you can use to build your own word embeddings on any corpus of text you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_en = stopwords.words('english')\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = re.sub('[^0-9a-zA-Z \\t]', '', txt)\n",
    "\n",
    "    return [word\n",
    "            for word in txt.lower().split()\n",
    "            if word not in stopwords_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['kings', 'queens', 'go', 'together'],\n",
       " ['men', 'women', 'go', 'together'],\n",
       " ['queens', 'women'],\n",
       " ['kings', 'men']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['kings and queens go together',\n",
    "        'men and women go together',\n",
    "        'queens are women',\n",
    "        'kings are men']\n",
    "\n",
    "docs_tokenized = [preprocess_text(doc) for doc in docs]\n",
    "docs_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "        docs_tokenized,\n",
    "        size=5,          # word embeddings length\n",
    "        window=5,        # window\n",
    "        min_count=1,     # ignores all words with total frequency lower than this\n",
    "        sg=0,            # 1 for skip-gram; otherwise CBOW\n",
    "        workers=1,\n",
    "        seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01952265,  0.04890453, -0.07217763,  0.00211847, -0.01218782],\n",
       "       [ 0.01659504,  0.09549649,  0.08556271,  0.00498654,  0.03865498],\n",
       "       [-0.01864961,  0.07124042, -0.05363773,  0.02688318, -0.05692117],\n",
       "       [ 0.02878875,  0.09254153, -0.07922063,  0.03018967, -0.07432565],\n",
       "       [ 0.02585494, -0.0624563 , -0.08489881,  0.02063094, -0.0851609 ],\n",
       "       [-0.07034413, -0.01507542,  0.03600588, -0.09823549, -0.01050054]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   kings [-0.01952265  0.04890453 -0.07217763  0.00211847 -0.01218782]\n",
      "  queens [0.01659504 0.09549649 0.08556271 0.00498654 0.03865498]\n",
      "      go [-0.01864961  0.07124042 -0.05363773  0.02688318 -0.05692117]\n",
      "together [ 0.02878875  0.09254153 -0.07922063  0.03018967 -0.07432565]\n",
      "     men [ 0.02585494 -0.0624563  -0.08489881  0.02063094 -0.0851609 ]\n",
      "   women [-0.07034413 -0.01507542  0.03600588 -0.09823549 -0.01050054]\n"
     ]
    }
   ],
   "source": [
    "for word in model.wv.vocab.keys():\n",
    "    print(\"{:>8s}\".format(word), model.wv[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('go', 0.8480280041694641),\n",
       " ('together', 0.7942909002304077),\n",
       " ('men', 0.29014742374420166)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"kings\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('together', -0.009249746799468994),\n",
       " ('go', -0.010827034711837769),\n",
       " ('women', -0.024528611451387405)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"queens\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queens', 0.3920442759990692),\n",
       " ('go', 0.15889883041381836),\n",
       " ('together', -0.042504362761974335)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kings - men + women = ?\n",
    "model.wv.most_similar(positive=['kings', 'women'], negative=['men'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not uncommon for research papers to report anywhere from 30% to 75% accuracy on analogy using tasks like these — where you count an analogy attempt as correct only if it guesses the exact word right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing word embeddings\n",
    "\n",
    "We can't visualize a 300 dimensional feature vector.  \n",
    "One of the popular things to do is to reduce it to a 2D space using t-sne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tsnescatterplot_closestwords(model, word):\n",
    "    vec    = model.wv[word]\n",
    "    arr    = np.empty((0,len(vec)), dtype='f')\n",
    "\n",
    "    # Add word to array\n",
    "    arr    = np.append(arr, np.array([vec]), axis=0)\n",
    "    labels = [word]\n",
    "    scores = [0]\n",
    "\n",
    "    # Add similar word to array\n",
    "    for item in model.wv.similar_by_word(word):\n",
    "        arr = np.append(arr, np.array([model.wv[item[0]]]), axis=0)\n",
    "        labels.append(item[0])\n",
    "        scores.append(item[1])\n",
    "        \n",
    "    # Reduce number of features to 2\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    X = tsne.fit_transform(arr)\n",
    "\n",
    "    # Plot points\n",
    "    x_coords = X[:, 0]\n",
    "    y_coords = X[:, 1]\n",
    "    plt.scatter(x_coords, y_coords, c=scores)\n",
    "\n",
    "    # Add labels\n",
    "    for label, x, y in zip(labels, x_coords, y_coords):\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y),\n",
    "            xytext=(5, -2),\n",
    "            textcoords='offset points')\n",
    "\n",
    "    # Remove ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    plt.xlim(xlim[0], xlim[1]+10)\n",
    "    plt.show()\n",
    "\n",
    "tsnescatterplot_closestwords(model, 'kings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the parallelogram analogy relationships will be broken by t-sne. It may hold true after a mapping through t-sne, but in most cases, because of t-sne non-linear mapping, you should not count on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing and loading word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kings', 'queens', 'go', 'together', 'men', 'women'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim comes with several already pre-trained moodels: https://radimrehurek.com/gensim/models/word2vec.html#usage-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Word2Vec\n",
    "\n",
    "Word2Vec is an algorithm to learn word embeddings, first introduced in the paper [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf) by Mikolov et al.,2013. \n",
    "\n",
    "1. Let's say we have the corpus below:\n",
    "\n",
    "        [\n",
    "            \"I want a glass of orange juice\",\n",
    "            \"You want a glass of apple juice\"\n",
    "        ]\n",
    "\n",
    "2. Convert the corpus to a list of tokenized word.\n",
    "\n",
    "        [\n",
    "            [\"i\", \"want\", \"a\", \"glass\", \"of\", \"orange\", \"juice\"],\n",
    "            [\"you\", \"want\", \"a\", \"glass\", \"of\", \"apple\", \"juice\"]\n",
    "        ]\n",
    "\n",
    "3. Retrieve the list of unique words in this corpus.  \n",
    "\n",
    "        [\"a\", \"apple\", \"glass\", \"i\", \"juice\", \"of\", \"orange\", \"want\", \"you\"]\n",
    "\n",
    "    This list's indexes will be used as basis to one-hot encode the words in the corpus.  \n",
    "    So if your corpus contains *V* unique words, each one-hot encoded vector will be 1×V dimensional. For example, the word \"a\", which appears first in the vocabulary, will be as the vector O<sub>1</sub> = [1,0,0,0,0,0,0,0,0]. The word \"apple”, which appears second in the vocabulary, will be encoded as the vector O<sub>2</sub> = [0,1,0,0,0,0,0,0,0]. Etc.<br><br>\n",
    "    \n",
    "4. Select a window size, *C*. We'll take C=1.  \n",
    "   In real-life applications, we usually choose a window size around 5 to 10<br><br>\n",
    "\n",
    "5. Two different approaches are proposed:  \n",
    "   * <ins>continuous bag-of-word [CBOW]</ins>:  \n",
    "     predicts the current word based on the context.\n",
    "\n",
    "     Take *C×2+1* words: the center word will be the current word and the words around are the context words. For example, for the first iteration: the context words are (\"i\", \"a\") and current word \"want\".  \n",
    "     One-hot encode the words, then use the context words as input, and the current word as target — to be fed to a neural network.\n",
    "     \n",
    "     Training complexity will be:  \n",
    "     `Q = (N×D + D×log2(V))`\n",
    "\n",
    "     ![](https://i.imgur.com/Wq3kvSP.png)\n",
    "    <br>\n",
    "\n",
    "   * <ins>skip-gram [SG]</ins>:  \n",
    "     predicts surrounding words given the current word.\n",
    "\n",
    "     Select randomly a number *R* in range [1,C] and then select *R* words before and *R* words after the current word as context words.\n",
    "     Increasing the range improves quality of the resulting word vectors, but it also increases the computational complexity. Since the more distant words are usually less related to the current word than those close to it, we give less weight to the distant words by sampling less from those words in our training examples.\n",
    "\n",
    "     Each current word as input will require us to do *R×2* word classifications with *R+R* words as target.\n",
    "\n",
    "     Training complexity will be proportional to:  \n",
    "     `Q = (1×D + D×log2(V)) × C`\n",
    "\n",
    "   So in both cases, you use a *current word* and *context words* that are one-hot encoded. In CBOW, the context words are inputs and the current word is the target. In skip-word, the current word is the input and the context words will be used as targets one after another.\n",
    "\n",
    "   You can choose any one of the two. When using continuous skip-grams, the order of context is taken into consideration. Because of this, the time it takes to train the word embeddings is slower than when using continuous bag-of-words. In general, CBOW is preferred for smaller corpus and is faster to train, while SG is slower but gives better results for large corpus and large dimensions.<br><br>\n",
    "\n",
    "6. With either the continuous bag-of-words or skip-grams representations as training data, word2vec then uses a shallow neural network with one hidden layer and one softmax output layer. The number of hidden nodes (D) will be the word embeddings dimension, so if your desired vector dimension is 3:\n",
    "\n",
    "        “i” => [0.001, 0.896, 0.763]\n",
    "\n",
    "    then the number of hidden layer node shall be 3.  \n",
    "    In real-life applications, we usually choose a vector size around 300\n",
    "\n",
    "    * <ins>Embedding matrix</ins>  \n",
    "      The end goal of all of this is really just to learn the hidden layer weight matrix (noted W or E), the weights of the output layer (W') we'll just toss when we're done.\n",
    "\n",
    "      If we take the weight matrix E (V×D) and multiply it by a single one-hot encoded vector O<sub>i</sub> (1×V), the result corresponds to the i<sup>th</sup> row (1×D). That row is going to be the embedding vector (e<sub>i</sub>) of the word corresponding to O<sub>i</sub> (O<sub>i</sub> × E = e<sub>i</sub> = i<sup>th</sup> row of E). This means that the weights of the hidden layer of this model is really just operating as a lookup table. For this reason, we also call the weight matrix of the hidden layer the *embedding matrix*.\n",
    "\n",
    "      ![](https://i.imgur.com/PGTKYDO.png)\n",
    "\n",
    "      Our one-hot encoded vector is a relatively high dimensional vector and most of these elements are zero so its actually not efficient to use a matrix vector multiplication to implement this — because we multiply a whole bunch of things by zeros. In practice, you would actually use a specialized function to just look up a column of the Embedding Matrix rather than do this with the matrix multiplication. In Keras for example, there's a `Embedding` layer that does just that.\n",
    "\n",
    "   * <ins>Softmax</ins>  \n",
    "     In case of a CBOW — having several word embeddings — we average the word embeddings generated by the first layer (or sum them depending on the implementation).\n",
    "     Then feed it to a softmax unit, which has its own weights (W'), to classify among all *V* possible words which one is the most likely. Each output neuron (one per word in our vocabulary) will produce an output between 0 and 1 and the sum of all these output values will add up to 1. The output node with the highest probability is our prediction.\n",
    "\n",
    "    ![](https://i.imgur.com/P8bDrUa.png)\n",
    "\n",
    "   * We initialise the different parameters (W, W') randomly then use gradient descent to learn all the parameters by repeatedly predicting the current word given the context words (or the other way around) and tweaking the parameters through backpropagation in order to maximize the likelihood of the training set.\n",
    "\n",
    "     Obviously, it isn't an easy learning problem, +/- 5 words around a given word could be a lot of different words. But the goal of setting this supervised learning problem isn't to do well on the supervised learning problem per se, we just want to use it to learn good word embeddings.\n",
    "     And it turns out this algorithm will learn pretty decent word embeddings: if two different words have very similar contexts, then our model needs to output very similar results for these two words, and one way for the network to output similar context predictions for these two words is if the word vectors are similar. So if two words have similar contexts, then it is the algorithm incentive to learn similar word vectors for these two words (to fit the training set better), which is exactly what we want.\n",
    "\n",
    "### Optimizations\n",
    "\n",
    "* You may have noticed that the neural network contains a huge number of weights. For 300 features and a vocab of 10,000 words, that's 3M weights in the hidden layer and output layer each. It doesn't matter much for the first layer, since we won't actually use the entire matrix, just retrieve the rows corresponding to the inputs, but the softmax is very expensive to compute. Every time you want to evaluate the probability of a given word, you need to carry out a sum over all words in your vocabulary. A few solutions have been proposed to this:\n",
    "\n",
    "  1. <ins>Hierarchical softmax</ins>: instead of trying to categorize something into all 10,000 categories in one go, it tells you if the target word in the first 5,000 words in the vocabulary or the last. Lets say this binary cost tells you it is in the first 5,000 words, the second pass will tell you is this in the first 2,500 or the second 2,500. And so on, until eventually you get down to classify the word. So the cost of the output layer is `D×log2(V)` instead of `D×V`.<br><br>\n",
    "\n",
    "  2. <ins>Negative sampling</ins>: we change the learning problem.  \n",
    "     Given a pair of words, we're going to predict if this is a context/target pair or not — for example orange/juice = 1, orange/king = 0. To generate the dataset:<br><br>\n",
    "\n",
    "     * pick a current word and context word, label that pair positive.\n",
    "     * take the same current word and pick *k* random words from the vocabulary list, label these pairs negative. It's okay if just by chance, one of the words picked at random from the dictionnary happen to appear in the window.\n",
    "\n",
    "       Mikolov & all recommend a value of *k* between 5 and 20 for smaller data sets, and 2 to 5 for larger datasets.\n",
    "\n",
    "     To choose negative examples:  \n",
    "     * We could sample it according to the empirical frequency of the words in the sample — how often each word appears in the corpus. The problem is that words such as \"the\", \"of\", \"a\" would be overrepresented and generate false negatives.\n",
    "     * We could use the uniform distribution — each words have the same probability of being chosen. But that's also very non-representative of the distribution of english words.\n",
    "     * What the authors reported to work best was to choose something in-between: have the probability of picking a word be proportional to its frequency (f(w<sub>i</sub>)) to the power 3/4.\n",
    "\n",
    "      $$\n",
    "      P(w_i) = \\frac{f(w_i)^{3/4}}{\\sum_{j=1}^{V} f(w_j)^{3/4}}\n",
    "      $$\n",
    "\n",
    "<ins>Keypoints</ins>:\n",
    "* It takes huge amount of resources to train and generate word embeddings.\n",
    "* To increase accuracy, we can:\n",
    "    * increase the training dataset\n",
    "    * increase the vector dimensions — more information will be preserved\n",
    "    * increase the window size\n",
    "* In real-life applications, we usually choose a window size around 5 to 10 and vector size around 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Negative sampling from scratch\n",
    "\n",
    "Source: https://github.com/shuuchen/keras_word2vec/blob/master/skip_gram.py\n",
    "\n",
    "<!-- \n",
    "https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html  \n",
    "-->\n",
    "\n",
    "### Corpus vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['kings', 'queens', 'go', 'together'],\n",
       " ['men', 'women', 'go', 'together'],\n",
       " ['queens', 'women'],\n",
       " ['kings', 'men']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['go', 'kings', 'men', 'queens', 'together', 'women'], dtype='<U8')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.unique(np.concatenate(docs_tokenized))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<UNK>', 'go', 'kings', 'men', 'queens', 'together', 'women'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.insert(vocab, 0, '<UNK>')\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'go': 1,\n",
       " 'kings': 2,\n",
       " 'men': 3,\n",
       " 'queens': 4,\n",
       " 'together': 5,\n",
       " 'women': 6}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = dict(zip(vocab, range(len(vocab))))\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 4, 1, 5], [3, 6, 1, 5], [4, 6], [2, 3]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_idx = [ [word2idx[w] for w in text] for text in docs_tokenized ]\n",
    "corpus_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative sampling pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    vocab_size = len(word2idx)\n",
    "\n",
    "    for sentence in corpus_idx:\n",
    "        data, labels = skipgrams(\n",
    "            sentence,\n",
    "            vocabulary_size=vocab_size,\n",
    "            window_size=5,\n",
    "            negative_samples=5,\n",
    "            shuffle=True,\n",
    "            seed=1\n",
    "        )\n",
    "        word_target, word_context = zip(*data)\n",
    "\n",
    "        yield ([\n",
    "            np.array(word_target).reshape(-1,1),\n",
    "            np.array(word_context).reshape(-1,1)],\n",
    "            np.array(labels).reshape(-1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['together', 'go', 'kings', 'together', 'queens']\n",
      "['women', 'women', 'men', 'men', 'go']\n",
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "(x1,x2),y = next(generate_data())\n",
    "\n",
    "print([vocab[w] for w in x1[:5].flatten()])\n",
    "print([vocab[w] for w in x2[:5].flatten()])\n",
    "print(y[:5].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding\n",
    "from tensorflow.keras.layers import dot as Dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_current (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_context (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embed_current (Embedding)       (None, 1, 5)         35          input_current[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embed_context (Embedding)       (None, 1, 5)         35          input_context[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dot)                     (None, 1, 1)         0           embed_current[0][0]              \n",
      "                                                                 embed_context[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Dense)                 (None, 1, 1)         2           embed[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D = 5\n",
    "\n",
    "# Hidden layer: embeddings\n",
    "input_current = Input(name='input_current', shape=(1, ))\n",
    "input_context = Input(name='input_context', shape=(1, ))\n",
    "\n",
    "embed_current = Embedding(\n",
    "        name='embed_current',\n",
    "        input_dim=len(word2idx),\n",
    "        input_length=1,\n",
    "        output_dim=D,\n",
    "        embeddings_initializer='glorot_uniform'\n",
    "    )(input_current)\n",
    "\n",
    "embed_context = Embedding(\n",
    "        name='embed_context',\n",
    "        input_dim=len(word2idx),\n",
    "        input_length=1,\n",
    "        output_dim=D,\n",
    "        embeddings_initializer='glorot_uniform'\n",
    "    )(input_context)\n",
    "\n",
    "embed = Dot(\n",
    "        name='embed',\n",
    "        inputs=[embed_current, embed_context],\n",
    "        normalize=True,\n",
    "        axes=2)\n",
    "\n",
    "# Output layer: sigmoid\n",
    "output = Dense(\n",
    "    name='sigmoid',\n",
    "    units=1,\n",
    "    activation='sigmoid',\n",
    "    kernel_initializer='glorot_uniform'\n",
    ")(embed)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[input_current, input_context], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7235\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7246\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7215\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7186\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7157\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.fit(generate_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_current',\n",
       " 'input_context',\n",
       " 'embed_current',\n",
       " 'embed_context',\n",
       " 'embed',\n",
       " 'sigmoid']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.name for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.46826714, -0.09341091,  0.36524528,  0.3354109 , -0.62853694],\n",
       "        [ 0.4128833 ,  0.6300215 , -0.26388356,  0.35105947,  0.47302455],\n",
       "        [ 0.50917906,  0.35099083,  0.5510756 , -0.64550126,  0.09453968],\n",
       "        [-0.14981388, -0.07302501,  0.07498515,  0.1698348 , -0.57571954],\n",
       "        [ 0.4989902 ,  0.18986508, -0.14864095, -0.6351667 ,  0.45919716],\n",
       "        [-0.17490853, -0.4230209 ,  0.6089475 ,  0.37923753, -0.08205611],\n",
       "        [ 0.26761794,  0.17720051,  0.03554806,  0.583754  ,  0.46797562]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights of the target (current) word embedding\n",
    "E = model.layers[2].get_weights()\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "      <td>0.468267</td>\n",
       "      <td>-0.093411</td>\n",
       "      <td>0.365245</td>\n",
       "      <td>0.335411</td>\n",
       "      <td>-0.628537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.412883</td>\n",
       "      <td>0.630022</td>\n",
       "      <td>-0.263884</td>\n",
       "      <td>0.351059</td>\n",
       "      <td>0.473025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kings</th>\n",
       "      <td>0.509179</td>\n",
       "      <td>0.350991</td>\n",
       "      <td>0.551076</td>\n",
       "      <td>-0.645501</td>\n",
       "      <td>0.094540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>-0.149814</td>\n",
       "      <td>-0.073025</td>\n",
       "      <td>0.074985</td>\n",
       "      <td>0.169835</td>\n",
       "      <td>-0.575720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queens</th>\n",
       "      <td>0.498990</td>\n",
       "      <td>0.189865</td>\n",
       "      <td>-0.148641</td>\n",
       "      <td>-0.635167</td>\n",
       "      <td>0.459197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>together</th>\n",
       "      <td>-0.174909</td>\n",
       "      <td>-0.423021</td>\n",
       "      <td>0.608948</td>\n",
       "      <td>0.379238</td>\n",
       "      <td>-0.082056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0.267618</td>\n",
       "      <td>0.177201</td>\n",
       "      <td>0.035548</td>\n",
       "      <td>0.583754</td>\n",
       "      <td>0.467976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4\n",
       "<UNK>     0.468267 -0.093411  0.365245  0.335411 -0.628537\n",
       "go        0.412883  0.630022 -0.263884  0.351059  0.473025\n",
       "kings     0.509179  0.350991  0.551076 -0.645501  0.094540\n",
       "men      -0.149814 -0.073025  0.074985  0.169835 -0.575720\n",
       "queens    0.498990  0.189865 -0.148641 -0.635167  0.459197\n",
       "together -0.174909 -0.423021  0.608948  0.379238 -0.082056\n",
       "women     0.267618  0.177201  0.035548  0.583754  0.467976"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(E[0], index=vocab)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>queens</th>\n",
       "      <td>0.498990</td>\n",
       "      <td>0.189865</td>\n",
       "      <td>-0.148641</td>\n",
       "      <td>-0.635167</td>\n",
       "      <td>0.459197</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0.267618</td>\n",
       "      <td>0.177201</td>\n",
       "      <td>0.035548</td>\n",
       "      <td>0.583754</td>\n",
       "      <td>0.467976</td>\n",
       "      <td>0.095365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.412883</td>\n",
       "      <td>0.630022</td>\n",
       "      <td>-0.263884</td>\n",
       "      <td>0.351059</td>\n",
       "      <td>0.473025</td>\n",
       "      <td>0.175121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kings</th>\n",
       "      <td>0.509179</td>\n",
       "      <td>0.350991</td>\n",
       "      <td>0.551076</td>\n",
       "      <td>-0.645501</td>\n",
       "      <td>0.094540</td>\n",
       "      <td>0.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "      <td>0.468267</td>\n",
       "      <td>-0.093411</td>\n",
       "      <td>0.365245</td>\n",
       "      <td>0.335411</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>0.514852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>together</th>\n",
       "      <td>-0.174909</td>\n",
       "      <td>-0.423021</td>\n",
       "      <td>0.608948</td>\n",
       "      <td>0.379238</td>\n",
       "      <td>-0.082056</td>\n",
       "      <td>1.611353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>-0.149814</td>\n",
       "      <td>-0.073025</td>\n",
       "      <td>0.074985</td>\n",
       "      <td>0.169835</td>\n",
       "      <td>-0.575720</td>\n",
       "      <td>1.985030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4  distance\n",
       "queens    0.498990  0.189865 -0.148641 -0.635167  0.459197  0.000000\n",
       "women     0.267618  0.177201  0.035548  0.583754  0.467976  0.095365\n",
       "go        0.412883  0.630022 -0.263884  0.351059  0.473025  0.175121\n",
       "kings     0.509179  0.350991  0.551076 -0.645501  0.094540  0.479800\n",
       "<UNK>     0.468267 -0.093411  0.365245  0.335411 -0.628537  0.514852\n",
       "together -0.174909 -0.423021  0.608948  0.379238 -0.082056  1.611353\n",
       "men      -0.149814 -0.073025  0.074985  0.169835 -0.575720  1.985030"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar words to \"queens\"\n",
    "vec = df.loc['queens'].values[:3]\n",
    "\n",
    "df['distance'] = df.apply(lambda x: cosine(x[:3], vec), axis=1)\n",
    "df.sort_values(by='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CBOW from scratch\n",
    "\n",
    "Source: [The Continuous Bag Of Words (CBOW) Model in NLP](https://analyticsindiamag.com/the-continuous-bag-of-words-cbow-model-in-nlp-hands-on-implementation-with-codes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-28 14:06:25--  https://raw.githubusercontent.com/bhoomikamadhukar/NLP/master/corona.txt\n",
      "Résolution de raw.githubusercontent.com (raw.githubusercontent.com)… 151.101.120.133\n",
      "Connexion à raw.githubusercontent.com (raw.githubusercontent.com)|151.101.120.133|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 1205 (1,2K) [text/plain]\n",
      "Enregistre : «corona.txt»\n",
      "\n",
      "corona.txt          100%[===================>]   1,18K  --.-KB/s    ds 0s      \n",
      "\n",
      "2020-11-28 14:06:25 (12,5 MB/s) - «corona.txt» enregistré [1205/1205]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/bhoomikamadhukar/NLP/master/corona.txt -O corona.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speed of transmission is an important point of difference between the two viruses. Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus. The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days. This means that influenza can spread faster than COVID-19. \r",
      "\r\n",
      "\r",
      "\r\n",
      "Further, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission. \r",
      "\r\n",
      "\r",
      "\r\n",
      "The reproductive number – the number of secondary infections generated from one infected individual – is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza. However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.  "
     ]
    }
   ],
   "source": [
    "!head corona.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize = Tokenizer()\n",
    "\n",
    "with open('corona.txt','r') as f:\n",
    "    sentences = [text for text in f if text.count(' ') >= 2]\n",
    "    vectorize.fit_on_texts(sentences)\n",
    "\n",
    "    data       = vectorize.texts_to_sequences(sentences)\n",
    "    vocab_size = len(vectorize.word_index) + 1\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 100)            10300     \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 103)               10403     \n",
      "=================================================================\n",
      "Total params: 20,703\n",
      "Trainable params: 20,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "vector_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=vector_size,\n",
    "    input_length=window_size*2\n",
    "))\n",
    "model.add(Lambda(\n",
    "    lambda x: K.mean(x, axis=1),\n",
    "    output_shape=(vector_size,)\n",
    "))\n",
    "model.add(Dense(\n",
    "    vocab_size,\n",
    "    activation='softmax'\n",
    "))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbow_model(data, window_size, vocab_size):\n",
    "    total_length = window_size*2\n",
    "\n",
    "    # Loop sentences\n",
    "    for text in data:\n",
    "        text_len = len(text)\n",
    "\n",
    "        # Loop current word\n",
    "        for idx, word in enumerate(text):\n",
    "            target  = [word]\n",
    "\n",
    "            # Get context words\n",
    "            begin   = min(idx - window_size, 0)\n",
    "            end     = min(idx + window_size + 1, text_len)\n",
    "\n",
    "            context = [[text[i]\n",
    "                         for i in range(begin, end)\n",
    "                         if i != idx]]\n",
    "\n",
    "            context_ = sequence.pad_sequences(context, maxlen=total_length)\n",
    "            target_  = to_categorical(target, vocab_size)\n",
    "\n",
    "            yield(context_, target_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 893.509485244751\n",
      "1 861.2343802452087\n",
      "2 811.7114593982697\n",
      "3 753.4938838481903\n",
      "4 696.3479005098343\n",
      "5 641.3203747272491\n",
      "6 587.1116592884064\n",
      "7 533.7495439052582\n",
      "8 482.1283251643181\n",
      "9 433.24124521017075\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(10):\n",
    "    cost = 0\n",
    "    for context, current in cbow_model(data, window_size, vocab_size):\n",
    "        cost += model.train_on_batch(context, current)\n",
    "\n",
    "    print(epoch, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "weights = model.get_weights()[0]\n",
    "\n",
    "f = open('vectors.txt' ,'w')\n",
    "f.write('{} {}\\n'.format(len(vectorize.word_index), vector_size))\n",
    "\n",
    "for word, i in vectorize.word_index.items():\n",
    "    f.write('{} {}\\n'.format(\n",
    "        word,\n",
    "        ' '.join(map(str, list(weights[i, :])))\n",
    "    ))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 100\r\n",
      "the -0.05488131 -0.23050767 0.3432513 0.33230445 -0.22281821 0.10457199 -0.06404924 -0.17461057 -0.40597138 -0.42399788 0.61719924 -0.3786851 0.2968675 -0.63962203 0.1659178 -0.48831302 0.10439325 -0.2937706 -0.19074214 -0.581508 0.4318212 -0.053948037 -0.12711203 0.29071498 -0.011745019 0.36633506 0.043478303 0.20287794 0.0002361493 0.26057664 -0.2417944 0.06788564 0.10677692 -0.07283654 -0.09534288 0.32987878 0.2135551 -0.47621754 0.10327092 0.32012042 -0.15416317 0.3006715 0.13319643 0.058463115 0.091162965 0.25433013 0.010104126 -0.121926375 0.16182046 0.1499127 -0.11833822 -0.24839404 0.27036768 0.28653297 0.10840813 0.121522464 -0.39882866 0.15432982 -0.45282605 -0.22696225 0.5189986 -0.13028798 -0.38684195 -0.26182812 0.3189917 0.6064083 -0.054251216 -0.41876674 0.55333257 0.44539213 0.17200229 -0.03611058 0.07110619 0.21874472 -0.44780388 -0.0076681464 0.2757156 0.1936903 0.23932174 -0.33215833 -0.31357375 -0.14005724 0.29270092 0.4368659 -0.1720954 -0.07559237 -0.115859665 0.08129932 -0.014224322 0.042222332 -0.07214841 0.22317822 0.008089537 0.25445902 -0.2421406 -0.2982478 0.31577247 -0.35610253 -0.0025462068 -0.44173136\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 vectors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–transmission', 0.6786088943481445),\n",
       " ('speed', 0.6244598627090454),\n",
       " ('important', 0.5908088684082031),\n",
       " ('major', 0.5672246217727661),\n",
       " ('difference', 0.4876672029495239),\n",
       " ('symptoms', 0.473138689994812),\n",
       " ('driver', 0.4378052353858948),\n",
       " ('or', 0.43168097734451294),\n",
       " ('point', 0.38322970271110535),\n",
       " ('appearance', 0.3795529007911682)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load embeddings into gensim\n",
    "model = KeyedVectors.load_word2vec_format('vectors.txt', binary=False)\n",
    "model.most_similar(positive=['transmission'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## word2phrase\n",
    "\n",
    "The [second word2vec paper](http://arxiv.org/pdf/1310.4546.pdf) also includes one more innovation worth discussing. The authors pointed out that a word pair like “Boston Globe” (a newspaper) has a much different meaning than the individual words “Boston” and “Globe”. So it makes sense to treat “Boston Globe”, wherever it occurs in the text, as a single word with its own word vector representation. Phrase detection is covered in the “Learning Phrases” section of their paper.\n",
    "\n",
    "More about it: [Word Pairs and “Phrases”](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/#word-pairs-and-phrases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
